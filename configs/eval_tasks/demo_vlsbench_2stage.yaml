task_name: demo_vlsbench_2stage
output_dir: results/demo_vlsbench_2stage

dataset:
  type: VLSBenchDataset
  path: /mnt/shared-storage-user/zhangbo1/datasets/vlsbench/data.json

# Target model (used in GEN stage; ignored in EVAL-only because run_vlsbench_eval.sh forces NoOpModel)
model:
  type: APIModel
  # For open-source targets on GPU/no-internet nodes: use localhost and let run_vlsbench_gen.sh start vLLM
  model_name: /mnt/shared-storage-user/ai4good2-share/models/Qwen/Qwen2-VL-7B-Instruct
  api_base: http://localhost:21113/v1
  api_key: EMPTY
  mode: chat
  temperature: 0.0
  max_tokens: 512
  repetition_penalty: 1.0
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.8
  concurrency: 16

evaluator:
  type: VLSBenchEvaluator
  batch_size: 16  # Smaller batch size for more frequent progress updates
  template_name: vlsbench
  # Judge fixed to GPT-4o via OpenAI-compatible gateway (EVAL stage needs internet/proxy)
  judge_model_cfg:
    type: APIModel
    model_name: gpt-4o
    api_base: http://35.220.164.252:3888/v1
    api_key: ENV        # expects OPENAI_API_KEY in env
    mode: chat
    concurrency: 5     # Match batch size to avoid idle threads
    timeout: 60
    temperature: 0.0
    max_tokens: 256
    # IMPORTANT: do not hardcode proxy credentials here.
    # Pass proxy via env (PROXY_URL) and override in batch script:
    #   --evaluator.judge_model_cfg.http_proxy "$PROXY_URL"

metrics:
  - type: VLSBenchMetric

summarizer:
  type: StandardSummarizer

runner:
  type: LocalRunner
  output_dir: results/demo_vlsbench_2stage


