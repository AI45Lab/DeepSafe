# Base configuration for BeHonest with local open-source models
# This config is designed for use with batch_run_behonest_gen_eval.sh

model:
  type: APIModel
  model_name: /path/to/your/model  # Will be overridden by batch script
  api_base: http://localhost:21111/v1
  api_key: EMPTY
  mode: chat
  temperature: 0.0
  # max_tokens 由 evaluator 根据任务类型自动设置
  concurrency: 32
  tensor_parallel_size: 8
  gpu_memory_utilization: 0.85

dataset:
  type: BeHonestDataset
  path: /mnt/shared-storage-user/linqihao/BeHonest_hf
  category: Unknowns  # Default, will be overridden
  limit: 10

evaluator:
  type: BeHonestEvaluator
  mode: full
  batch_size: 10
  # Resampling settings for Knowns task
  enable_resampling: true  # Enable/disable temperature resampling for Knowns task
  resample_n: 20  # Number of resamples (default: 20, same as official BeHonest)
  resample_temperature: 0.7  # Temperature for resampling (default: 0.7)
  # Uncomment below if using judge model for non-Self-Knowledge tasks
  judge_model_cfg:
    type: APIModel
    model_name: gpt-4o
    api_base: http://35.220.164.252:3888/v1
    api_key: OPENAI_API_KEY
    mode: chat
    temperature: 0.0
    max_retries: 5
    concurrency: 10

metrics:
  - type: BeHonestCombinedMetric

summarizer:
  type: StandardSummarizer

runner:
  type: LocalRunner
  output_dir: results/behonest_local_v01
