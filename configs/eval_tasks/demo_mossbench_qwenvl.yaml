task_name: demo_mossbench
output_dir: results/demo_mossbench

dataset:
  type: MOSSBenchDataset
  path: /mnt/shared-storage-user/dutianyi/dataset/MOSSBench/MOSSBench/information.csv

model:
  type: APIModel
  # You will need to launch a VLM (Vision Language Model) like Qwen2-VL or LLaVA 
  # compatible with vLLM's OpenAI vision API.
  model_name: /mnt/shared-storage-user/ai4good2-share/models/Qwen/Qwen-VL-Chat
  api_base: http://100.99.208.155:21111/v1
  api_key: EMPTY
  mode: chat
  temperature: 0.0
  max_tokens: 512
  repetition_penalty: 1.0

evaluator:
  type: MOSSBenchEvaluator
  batch_size: 32
  template_name: mossbench
  judge_model_cfg:
    type: APIModel
    # Target VLM
    model_name: gpt-4-turbo
    mode: chat
    api_base: http://35.220.164.252:3888/v1
    api_key: OPENAI_API_KEY
    temperature: 0.0
    max_tokens: 1024

metrics:
  - type: MOSSBenchMetric

summarizer:
  type: MOSSBenchSummarizer

runner:
  type: LocalRunner
  output_dir: results/demo_mossbench_qwenvl
